"""
ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ vs ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã®æ¯”è¼ƒåˆ†æ
Comparison Analysis: Semantic Search vs Keyword Search
"""

import json
import pandas as pd
from pathlib import Path
from datetime import datetime

def load_comparison_results(json_file: Path):
    """æ¯”è¼ƒçµæœã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    with open(json_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def analyze_performance(results):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ"""
    
    print("="*80)
    print("ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ vs ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ - æ€§èƒ½æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ")
    print("Performance Comparison Report: Semantic vs Keyword Search")
    print("="*80)
    print()
    
    # ãƒ‡ãƒ¼ã‚¿åé›†
    keyword_times = []
    semantic_times = []
    hybrid_times = []
    keyword_scores = []
    semantic_scores = []
    hybrid_scores = []
    
    query_details = []
    
    for result in results:
        query_id = result['query_id']
        query = result['query']
        
        # é€Ÿåº¦ãƒ‡ãƒ¼ã‚¿
        kw_time = result['keyword']['time']
        sem_time = result['semantic']['time']
        hyb_time = result['hybrid']['time']
        
        keyword_times.append(kw_time)
        semantic_times.append(sem_time)
        hybrid_times.append(hyb_time)
        
        # ã‚¹ã‚³ã‚¢ãƒ‡ãƒ¼ã‚¿
        kw_score = result['keyword']['top_score']
        sem_score = result['semantic']['top_score']
        hyb_score = result['hybrid']['top_score']
        
        keyword_scores.append(kw_score)
        semantic_scores.append(sem_score)
        hybrid_scores.append(hyb_score)
        
        # ãƒˆãƒƒãƒ—çµæœã®ãƒãƒ¼ãƒ‰ID
        kw_top = result['keyword']['top_results'][0]['node_id'] if result['keyword']['top_results'] else 'N/A'
        sem_top = result['semantic']['top_results'][0]['node_id'] if result['semantic']['top_results'] else 'N/A'
        hyb_top = result['hybrid']['top_results'][0]['node_id'] if result['hybrid']['top_results'] else 'N/A'
        
        query_details.append({
            'id': query_id,
            'query': query[:60] + '...' if len(query) > 60 else query,
            'kw_time': kw_time,
            'sem_time': sem_time,
            'hyb_time': hyb_time,
            'kw_score': kw_score,
            'sem_score': sem_score,
            'hyb_score': hyb_score,
            'kw_top': kw_top,
            'sem_top': sem_top,
            'hyb_top': hyb_top,
            'same_top': kw_top == sem_top
        })
    
    # 1. é€Ÿåº¦æ¯”è¼ƒ
    print("ğŸ“Š 1. æ¤œç´¢é€Ÿåº¦ã®æ¯”è¼ƒ (Search Speed Comparison)")
    print("-" * 80)
    print(f"{'æ‰‹æ³•':<20} {'å¹³å‡æ™‚é–“':>12} {'æœ€å°æ™‚é–“':>12} {'æœ€å¤§æ™‚é–“':>12} {'æ¨™æº–åå·®':>12}")
    print("-" * 80)
    
    import numpy as np
    
    print(f"{'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢':<20} {np.mean(keyword_times):>11.4f}s {np.min(keyword_times):>11.4f}s {np.max(keyword_times):>11.4f}s {np.std(keyword_times):>11.4f}s")
    print(f"{'ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢':<20} {np.mean(semantic_times):>11.4f}s {np.min(semantic_times):>11.4f}s {np.max(semantic_times):>11.4f}s {np.std(semantic_times):>11.4f}s")
    print(f"{'ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢':<20} {np.mean(hybrid_times):>11.4f}s {np.min(hybrid_times):>11.4f}s {np.max(hybrid_times):>11.4f}s {np.std(hybrid_times):>11.4f}s")
    
    print()
    print("âš¡ é€Ÿåº¦æ¯”ç‡ (Speed Ratio):")
    sem_ratio = np.mean(semantic_times) / np.mean(keyword_times)
    hyb_ratio = np.mean(hybrid_times) / np.mean(keyword_times)
    print(f"  ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ / ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: {sem_ratio:.2f}x")
    print(f"  ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ / ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: {hyb_ratio:.2f}x")
    
    # 2. ã‚¹ã‚³ã‚¢æ¯”è¼ƒ
    print()
    print("ğŸ“ˆ 2. æ¤œç´¢ç²¾åº¦ã®æ¯”è¼ƒ (Search Accuracy Comparison)")
    print("-" * 80)
    print(f"{'æ‰‹æ³•':<20} {'å¹³å‡ã‚¹ã‚³ã‚¢':>12} {'æœ€å°ã‚¹ã‚³ã‚¢':>12} {'æœ€å¤§ã‚¹ã‚³ã‚¢':>12} {'æ¨™æº–åå·®':>12}")
    print("-" * 80)
    
    print(f"{'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢':<20} {np.mean(keyword_scores):>12.4f} {np.min(keyword_scores):>12.4f} {np.max(keyword_scores):>12.4f} {np.std(keyword_scores):>12.4f}")
    print(f"{'ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢':<20} {np.mean(semantic_scores):>12.4f} {np.min(semantic_scores):>12.4f} {np.max(semantic_scores):>12.4f} {np.std(semantic_scores):>12.4f}")
    print(f"{'ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢':<20} {np.mean(hybrid_scores):>12.4f} {np.min(hybrid_scores):>12.4f} {np.max(hybrid_scores):>12.4f} {np.std(hybrid_scores):>12.4f}")
    
    print()
    print("âš ï¸ æ³¨æ„: ã‚¹ã‚³ã‚¢ã®å°ºåº¦ãŒç•°ãªã‚‹ãŸã‚ç›´æ¥æ¯”è¼ƒã¯ã§ãã¾ã›ã‚“")
    print("   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: ãƒãƒƒãƒå˜èªæ•° (æ•´æ•°)")
    print("   ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢: ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ (0-1)")
    print("   ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢: é‡ã¿ä»˜ã‘åˆæˆã‚¹ã‚³ã‚¢ (0-1)")
    
    # 3. ã‚¯ã‚¨ãƒªåˆ¥è©³ç´°
    print()
    print("ğŸ“‹ 3. ã‚¯ã‚¨ãƒªåˆ¥ã®è©³ç´°æ¯”è¼ƒ (Query-by-Query Details)")
    print("-" * 80)
    
    for detail in query_details:
        print(f"\nQ{detail['id']}: {detail['query']}")
        print(f"  é€Ÿåº¦: KW={detail['kw_time']:.4f}s, SEM={detail['sem_time']:.4f}s, HYB={detail['hyb_time']:.4f}s")
        print(f"  ã‚¹ã‚³ã‚¢: KW={detail['kw_score']:.4f}, SEM={detail['sem_score']:.4f}, HYB={detail['hyb_score']:.4f}")
        print(f"  ãƒˆãƒƒãƒ—çµæœ: KW={detail['kw_top']}, SEM={detail['sem_top']}, HYB={detail['hyb_top']}")
        
        if detail['same_top']:
            print(f"  âœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã§åŒã˜ãƒˆãƒƒãƒ—çµæœ")
        else:
            print(f"  âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã§ç•°ãªã‚‹ãƒˆãƒƒãƒ—çµæœ")
    
    # 4. ä¸€è‡´ç‡åˆ†æ
    print()
    print("ğŸ¯ 4. ãƒˆãƒƒãƒ—çµæœã®ä¸€è‡´ç‡ (Top Result Agreement)")
    print("-" * 80)
    
    same_count = sum(1 for d in query_details if d['same_top'])
    agreement_rate = (same_count / len(query_details)) * 100
    
    print(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã¨ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã§ãƒˆãƒƒãƒ—çµæœãŒä¸€è‡´: {same_count}/{len(query_details)} ({agreement_rate:.1f}%)")
    
    # 5. æ¨å¥¨äº‹é …
    print()
    print("ğŸ’¡ 5. æ¨å¥¨äº‹é …ã¨çµè«– (Recommendations & Conclusions)")
    print("="*80)
    
    if sem_ratio < 1.5:
        print("âœ… ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã®é€Ÿåº¦ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã¯è¨±å®¹ç¯„å›²å†… (<1.5x)")
    else:
        print(f"âš ï¸ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã¯{sem_ratio:.1f}å€é…ã„ - ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ã‚’æ¨å¥¨")
    
    if agreement_rate > 70:
        print(f"âœ… é«˜ã„ä¸€è‡´ç‡({agreement_rate:.1f}%) - ä¸¡æ‰‹æ³•ã¯é¡ä¼¼ã®çµæœã‚’è¿”ã™")
    elif agreement_rate > 40:
        print(f"âš ï¸ ä¸­ç¨‹åº¦ã®ä¸€è‡´ç‡({agreement_rate:.1f}%) - ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ãŒç•°ãªã‚‹è¦–ç‚¹ã‚’æä¾›")
    else:
        print(f"âŒ ä½ã„ä¸€è‡´ç‡({agreement_rate:.1f}%) - æ‰‹æ³•ã®é•ã„ãŒå¤§ãã„")
    
    print()
    print("ğŸ“Œ ç·åˆæ¨å¥¨:")
    print("  1. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’æ¨å¥¨ - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®é«˜é€Ÿæ€§ã¨ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã®ç²¾åº¦ã‚’ä¸¡ç«‹")
    print("  2. é‡ã¿èª¿æ•´: keyword_weight=0.4, semantic_weight=0.6 ãŒç¾åœ¨ã®è¨­å®š")
    print("  3. åŸ‹ã‚è¾¼ã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ´»ç”¨ã§åˆå›ä»¥é™ã®é€Ÿåº¦ã‚’æ”¹å–„")
    
    print()
    print("="*80)

def main():
    # æœ€æ–°ã®æ¯”è¼ƒçµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    results_dir = Path("results")
    comparison_files = sorted(results_dir.glob("semantic_search_comparison_*.json"))
    
    if not comparison_files:
        print("âŒ ã‚¨ãƒ©ãƒ¼: æ¯”è¼ƒçµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    latest_file = comparison_files[-1]
    print(f"ğŸ“‚ åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {latest_file.name}\n")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    results = load_comparison_results(latest_file)
    
    # åˆ†æå®Ÿè¡Œ
    analyze_performance(results)
    
    # CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    export_to_csv = True
    if export_to_csv:
        csv_file = results_dir / f"comparison_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        data = []
        for result in results:
            data.append({
                'Query_ID': result['query_id'],
                'Query': result['query'],
                'Keyword_Time': result['keyword']['time'],
                'Semantic_Time': result['semantic']['time'],
                'Hybrid_Time': result['hybrid']['time'],
                'Keyword_Score': result['keyword']['top_score'],
                'Semantic_Score': result['semantic']['top_score'],
                'Hybrid_Score': result['hybrid']['top_score'],
                'Keyword_Top': result['keyword']['top_results'][0]['node_id'] if result['keyword']['top_results'] else 'N/A',
                'Semantic_Top': result['semantic']['top_results'][0]['node_id'] if result['semantic']['top_results'] else 'N/A',
                'Hybrid_Top': result['hybrid']['top_results'][0]['node_id'] if result['hybrid']['top_results'] else 'N/A'
            })
        
        df = pd.DataFrame(data)
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ CSVå‡ºåŠ›: {csv_file}")

if __name__ == "__main__":
    main()
