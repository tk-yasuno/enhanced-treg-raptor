#!/usr/bin/env python3
"""ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµ±è¨ˆç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""
import json
from pathlib import Path

# æœ€æ–°ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
results_dir = Path("results")
json_files = list(results_dir.glob("enhanced_treg_raptor_80x_*.json"))
if not json_files:
    print("çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    exit(1)

latest_file = max(json_files, key=lambda p: p.stat().st_mtime)
print(f"ğŸ“ çµæœãƒ•ã‚¡ã‚¤ãƒ«: {latest_file.name}\n")

# JSONèª­ã¿è¾¼ã¿
with open(latest_file, 'r', encoding='utf-8') as f:
    data = json.load(f)

# ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµ±è¨ˆ
stats = data.get('clustering_stats', {})
print("=" * 70)
print("ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å“è³ªçµ±è¨ˆ (Silhouette 0.5 + DBI 0.5, k=2~5)")
print("=" * 70)

if 'avg_silhouette' in stats:
    print(f"  âœ“ å¹³å‡Silhouette: {stats['avg_silhouette']:.4f}")
    print(f"    â””â”€ ç¯„å›²: -1 (æœ€æ‚ª) ~ 1 (æœ€è‰¯)")
    print(f"    â””â”€ é«˜ã„ã»ã©ã‚¯ãƒ©ã‚¹ã‚¿å†…å‡é›†åº¦ãŒé«˜ãã€ã‚¯ãƒ©ã‚¹ã‚¿é–“åˆ†é›¢ãŒè‰¯ã„\n")
    
    print(f"  âœ“ å¹³å‡DBI (Davies-Bouldin Index): {stats['avg_dbi']:.4f}")
    print(f"    â””â”€ ç¯„å›²: 0 (æœ€è‰¯) ~ âˆ (æœ€æ‚ª)")
    print(f"    â””â”€ ä½ã„ã»ã©ã‚¯ãƒ©ã‚¹ã‚¿ãŒå¯†é›†ã—ã¦ã„ã¦åˆ†é›¢ã—ã¦ã„ã‚‹\n")
    
    print(f"  âœ“ å¹³å‡ã‚¯ãƒ©ã‚¹ã‚¿æ•°: {stats['avg_k']:.1f}")
    print(f"  âœ“ è©•ä¾¡å›æ•°: {len(stats.get('silhouette_scores', []))}")
    
    # ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
    sil_scores = stats.get('silhouette_scores', [])
    dbi_scores = stats.get('dbi_scores', [])
    k_values = stats.get('selected_k_values', [])
    
    if sil_scores:
        import numpy as np
        print(f"\n  ğŸ“ˆ ã‚¹ã‚³ã‚¢åˆ†å¸ƒ:")
        print(f"    Silhouette: min={min(sil_scores):.3f}, max={max(sil_scores):.3f}, std={np.std(sil_scores):.3f}")
        print(f"    DBI: min={min(dbi_scores):.3f}, max={max(dbi_scores):.3f}, std={np.std(dbi_scores):.3f}")
        print(f"    ã‚¯ãƒ©ã‚¹ã‚¿æ•°: min={min(k_values)}, max={max(k_values)}, std={np.std(k_values):.1f}")
else:
    print("  âš ï¸ çµ±è¨ˆæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# ãƒ„ãƒªãƒ¼æƒ…å ±
print("\n" + "=" * 70)
print("ğŸŒ³ RAPTOR ãƒ„ãƒªãƒ¼æ§‹é€ ")
print("=" * 70)
print(f"  ç·ãƒãƒ¼ãƒ‰æ•°: {data.get('total_nodes', 'N/A')}")
print(f"  ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰æ•°: {data.get('leaf_count', 'N/A')} (å…ƒæ–‡æ›¸)")
print(f"  å†…éƒ¨ãƒãƒ¼ãƒ‰æ•°: {data.get('total_nodes', 0) - data.get('leaf_count', 0)} (ã‚¯ãƒ©ã‚¹ã‚¿è¦ç´„)")
print(f"  ãƒ„ãƒªãƒ¼æ·±ã•: {data.get('max_depth', 'N/A')}")
print(f"  æ§‹ç¯‰æ™‚é–“: {data.get('build_time_seconds', 'N/A'):.1f}ç§’")

# ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ
level_dist = data.get('level_distribution', {})
if level_dist:
    print("\n  ğŸ“Š Tregãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ:")
    for level, count in sorted(level_dist.items(), key=lambda x: int(x[0])):
        pct = (count / data.get('total_documents', 1)) * 100
        print(f"    Level {level}: {count:4d} docs ({pct:5.1f}%)")

print("\n" + "=" * 70)
